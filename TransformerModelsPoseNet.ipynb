{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0894ac1b-854e-4c08-a52d-c7a77e5fa40a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "51bf9d7a-7a2d-4336-8927-f7681d3d3c88",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import splitfolders\n",
    "# splitfolders.ratio(\"D:\\\\Stroke Data\", output=\"D:\\\\Stroke Data_Splitted\\\\\",seed=1337, ratio=(.7, .3), group_prefix=None, move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca907370-c6bc-4ea9-8a2b-52c0a84e970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, MultiHeadAttention, LayerNormalization, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load your datasets\n",
    "Straight_Drive_df = pd.read_csv(\"Straight_Drive.csv\")\n",
    "Sweep_df = pd.read_csv(\"Sweep.csv\")\n",
    "Pull_df = pd.read_csv(\"Pull.csv\")\n",
    "onDrive_df = pd.read_csv(\"onDrive.csv\")\n",
    "Flick_df = pd.read_csv(\"Flick.csv\")\n",
    "Cut_df = pd.read_csv(\"Cut.csv\")\n",
    "Cover_Drive_df = pd.read_csv(\"Cover_Drive.csv\")\n",
    "back_foot_punch_df = pd.read_csv(\"back_foot_punch.csv\")\n",
    "\n",
    "# Using 'Cover_Drive.csv' dataset\n",
    "Posdataset = pd.read_csv('Cover_Drive.csv')\n",
    "# Drop the non-numeric columns ('Unnamed: 0' and 'Label')\n",
    "Posdataset_numeric = Posdataset.drop(columns=['Unnamed: 0', 'Label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86fbc570-e5e9-4112-82c6-7cf0df61689d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F0_x</th>\n",
       "      <th>F0_y</th>\n",
       "      <th>F0_z</th>\n",
       "      <th>F0_vis</th>\n",
       "      <th>F1_x</th>\n",
       "      <th>F1_y</th>\n",
       "      <th>F1_z</th>\n",
       "      <th>F1_vis</th>\n",
       "      <th>F2_x</th>\n",
       "      <th>F2_y</th>\n",
       "      <th>...</th>\n",
       "      <th>F30_z</th>\n",
       "      <th>F30_vis</th>\n",
       "      <th>F31_x</th>\n",
       "      <th>F31_y</th>\n",
       "      <th>F31_z</th>\n",
       "      <th>F31_vis</th>\n",
       "      <th>F32_x</th>\n",
       "      <th>F32_y</th>\n",
       "      <th>F32_z</th>\n",
       "      <th>F32_vis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.605604</td>\n",
       "      <td>0.319193</td>\n",
       "      <td>-0.206423</td>\n",
       "      <td>0.998100</td>\n",
       "      <td>0.608060</td>\n",
       "      <td>0.310672</td>\n",
       "      <td>-0.205325</td>\n",
       "      <td>0.997993</td>\n",
       "      <td>0.609513</td>\n",
       "      <td>0.310109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052371</td>\n",
       "      <td>0.704735</td>\n",
       "      <td>0.636576</td>\n",
       "      <td>0.643802</td>\n",
       "      <td>-0.210230</td>\n",
       "      <td>0.918661</td>\n",
       "      <td>0.629231</td>\n",
       "      <td>0.632027</td>\n",
       "      <td>0.011629</td>\n",
       "      <td>0.861975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.605210</td>\n",
       "      <td>0.320216</td>\n",
       "      <td>-0.195480</td>\n",
       "      <td>0.998275</td>\n",
       "      <td>0.607313</td>\n",
       "      <td>0.310882</td>\n",
       "      <td>-0.193891</td>\n",
       "      <td>0.998183</td>\n",
       "      <td>0.608708</td>\n",
       "      <td>0.310283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000988</td>\n",
       "      <td>0.693936</td>\n",
       "      <td>0.637445</td>\n",
       "      <td>0.648802</td>\n",
       "      <td>-0.216752</td>\n",
       "      <td>0.922947</td>\n",
       "      <td>0.629856</td>\n",
       "      <td>0.631912</td>\n",
       "      <td>-0.047416</td>\n",
       "      <td>0.844693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.605156</td>\n",
       "      <td>0.321100</td>\n",
       "      <td>-0.198475</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>0.607107</td>\n",
       "      <td>0.311066</td>\n",
       "      <td>-0.197096</td>\n",
       "      <td>0.998352</td>\n",
       "      <td>0.608519</td>\n",
       "      <td>0.310419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>0.685689</td>\n",
       "      <td>0.637536</td>\n",
       "      <td>0.646330</td>\n",
       "      <td>-0.215665</td>\n",
       "      <td>0.927065</td>\n",
       "      <td>0.630199</td>\n",
       "      <td>0.631907</td>\n",
       "      <td>-0.039618</td>\n",
       "      <td>0.830709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.602378</td>\n",
       "      <td>0.320967</td>\n",
       "      <td>-0.149304</td>\n",
       "      <td>0.998564</td>\n",
       "      <td>0.604508</td>\n",
       "      <td>0.311048</td>\n",
       "      <td>-0.147209</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.605890</td>\n",
       "      <td>0.310358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022291</td>\n",
       "      <td>0.679551</td>\n",
       "      <td>0.637206</td>\n",
       "      <td>0.644141</td>\n",
       "      <td>-0.173419</td>\n",
       "      <td>0.930712</td>\n",
       "      <td>0.631187</td>\n",
       "      <td>0.631652</td>\n",
       "      <td>-0.020749</td>\n",
       "      <td>0.814591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600436</td>\n",
       "      <td>0.320933</td>\n",
       "      <td>-0.092031</td>\n",
       "      <td>0.998703</td>\n",
       "      <td>0.602337</td>\n",
       "      <td>0.311165</td>\n",
       "      <td>-0.096430</td>\n",
       "      <td>0.998647</td>\n",
       "      <td>0.603642</td>\n",
       "      <td>0.310417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083066</td>\n",
       "      <td>0.685475</td>\n",
       "      <td>0.637198</td>\n",
       "      <td>0.642320</td>\n",
       "      <td>-0.159816</td>\n",
       "      <td>0.936338</td>\n",
       "      <td>0.632738</td>\n",
       "      <td>0.629347</td>\n",
       "      <td>0.058007</td>\n",
       "      <td>0.807283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       F0_x      F0_y      F0_z    F0_vis      F1_x      F1_y      F1_z  \\\n",
       "0  0.605604  0.319193 -0.206423  0.998100  0.608060  0.310672 -0.205325   \n",
       "1  0.605210  0.320216 -0.195480  0.998275  0.607313  0.310882 -0.193891   \n",
       "2  0.605156  0.321100 -0.198475  0.998430  0.607107  0.311066 -0.197096   \n",
       "3  0.602378  0.320967 -0.149304  0.998564  0.604508  0.311048 -0.147209   \n",
       "4  0.600436  0.320933 -0.092031  0.998703  0.602337  0.311165 -0.096430   \n",
       "\n",
       "     F1_vis      F2_x      F2_y  ...     F30_z   F30_vis     F31_x     F31_y  \\\n",
       "0  0.997993  0.609513  0.310109  ...  0.052371  0.704735  0.636576  0.643802   \n",
       "1  0.998183  0.608708  0.310283  ... -0.000988  0.693936  0.637445  0.648802   \n",
       "2  0.998352  0.608519  0.310419  ...  0.006449  0.685689  0.637536  0.646330   \n",
       "3  0.998500  0.605890  0.310358  ...  0.022291  0.679551  0.637206  0.644141   \n",
       "4  0.998647  0.603642  0.310417  ...  0.083066  0.685475  0.637198  0.642320   \n",
       "\n",
       "      F31_z   F31_vis     F32_x     F32_y     F32_z   F32_vis  \n",
       "0 -0.210230  0.918661  0.629231  0.632027  0.011629  0.861975  \n",
       "1 -0.216752  0.922947  0.629856  0.631912 -0.047416  0.844693  \n",
       "2 -0.215665  0.927065  0.630199  0.631907 -0.039618  0.830709  \n",
       "3 -0.173419  0.930712  0.631187  0.631652 -0.020749  0.814591  \n",
       "4 -0.159816  0.936338  0.632738  0.629347  0.058007  0.807283  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Posdataset_numeric.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a971f6-5869-44f8-89b4-1584a327ef92",
   "metadata": {},
   "source": [
    "Let's break this code down step by step and explain with an example using **numeric values**.\r\n",
    "\r\n",
    "### Problem Context\r\n",
    "- We have a dataset `Posdataset_numeric`, where each row corresponds to a \"frame\" (e.g., keypoints of a cricket stroke).\r\n",
    "- Each frame has `n_features = 4` features (which could represent coordinates or other numeric data).\r\n",
    "- We're using a sliding window of `timesteps = 5` to predict the next frame.\r\n",
    "- We'll train our model using the first 25 frames and test it on the next 7 frames.\r\n",
    "\r\n",
    "### Key Concepts\r\n",
    "\r\n",
    "- **Timesteps**: The number of past frames (i.e., 5) used to predict the next one.\r\n",
    "- **Training Set**: The first 25 frames used for training.\r\n",
    "- **Test Set**: The next 7 frames used to evaluate the model.\r\n",
    "\r\n",
    "### Example Data\r\n",
    "Assume our dataset (`Posdataset_numeric`) looks like this (simplified with random values):\r\n",
    "\r\n",
    "```\r\n",
    "Frame | Feature1 | Feature2 | Feature3 | Feature4\r\n",
    "---------------------------------------------------\r\n",
    "1     | 0.1      | 0.2      | 0.3      | 0.4\r\n",
    "2     | 0.5      | 0.6      | 0.7      | 0.8\r\n",
    "3     | 0.9      | 1.0      | 1.1      | 1.2\r\n",
    "4     | 1.3      | 1.4      | 1.5      | 1.6\r\n",
    "5     | 1.7      | 1.8      | 1.9      | 2.0\r\n",
    "6     | 2.1      | 2.2      | 2.3      | 2.4\r\n",
    "7     | 2.5      | 2.6      | 2.7      | 2.8\r\n",
    "...\r\n",
    "32    | 9.7      | 9.8      | 9.9      | 10.0\r\n",
    "```\r\n",
    "\r\n",
    "### Data Splitting\r\n",
    "1. **Training Set** (`train_size = 25`): This includes the first 25 frames (rows 1 to 25).\r\n",
    "2. **Test Set** (`test_size = 7`): This includes the next 7 frames (rows 26 to 32).\r\n",
    "\r\n",
    "```python\r\n",
    "train_data = Posdataset_numeric.iloc[:25].values  # First 25 rows\r\n",
    "test_data = Posdataset_numeric.iloc[25:32].values # Next 7 rows\r\n",
    "```\r\n",
    "\r\n",
    "### Sequence Creation\r\n",
    "The function `create_sequences` generates sequences (subsets of the data) for input (X) and target output (y).\r\n",
    "\r\n",
    "- **X**: Contains 5 consecutive frames (as defined by `timesteps = 5`).\r\n",
    "- **y**: Contains the next frame to predict (i.e., the frame that comes after the 5th frame in the sequence).\r\n",
    "\r\n",
    "#### Training Set Example:\r\n",
    "Let's consider the **first sequence** generated from the training set (`train_data`).\r\n",
    "\r\n",
    "- **X** (first sequence): Frames 1 to 5 (each frame has 4 features):\r\n",
    "  ```\r\n",
    "  [[0.1, 0.2, 0.3, 0.4], \r\n",
    "   [0.5, 0.6, 0.7, 0.8], \r\n",
    "   [0.9, 1.0, 1.1, 1.2], \r\n",
    "   [1.3, 1.4, 1.5, 1.6], \r\n",
    "   [1.7, 1.8, 1.9, 2.0]]\r\n",
    "  ```\r\n",
    "- **y** (first target): Frame 6 (the next frame):\r\n",
    "  ```\r\n",
    "  [2.1, 2.2, 2.3, 2.4]\r\n",
    "  ```\r\n",
    "\r\n",
    "The function repeats this process, sliding the window over the data to create additional sequences.\r\n",
    "\r\n",
    "#### Final Shape:\r\n",
    "After generating all possible sequences in the training data:\r\n",
    "- **X_train shape**: `(20, 5, 4)` → 20 sequences, each containing 5 frames, with 4 features per frame.\r\n",
    "- **y_train shape**: `(20, 4)` → 20 target frames, each with 4 features.\r\n",
    "\r\n",
    "#### Test Set Example:\r\n",
    "For the test data (`test_data`):\r\n",
    "- The same sliding window approach is applied, using the first 5 test frames to predict the 6th one, and so on.\r\n",
    "\r\n",
    "### Code Walkthrough:\r\n",
    "\r\n",
    "```python\r\n",
    "# Parameters\r\n",
    "timesteps = 5  # Use 5 previous frames for prediction\r\n",
    "n_features = 4  # Each frame has 4 features\r\n",
    "train_size = 25\r\n",
    "test_size = 7\r\n",
    "\r\n",
    "# Split the data into training and test sets\r\n",
    "train_data = Posdataset_numeric.iloc[:train_size].values  # First 25 frames\r\n",
    "test_data = Posdataset_numeric.iloc[train_size:train_size + test_size].values  # Next 7 frames\r\n",
    "\r\n",
    "# Function to create sequences (X as input, y as target)\r\n",
    "def create_sequences(data, timesteps):\r\n",
    "    X, y = [], []\r\n",
    "    for i in range(len(data) - timesteps):\r\n",
    "        X.append(data[i:i + timesteps])  # 5 frames as input\r\n",
    "        y.append(data[i + timesteps])    # The next frame as output\r\n",
    "    return np.array(X), np.array(y)\r\n",
    "\r\n",
    "# Create sequences for training\r\n",
    "X_train, y_train = create_sequences(train_data, timesteps)\r\n",
    "# Create sequences for testing\r\n",
    "X_test, y_test = create_sequences(test_data, timesteps)\r\n",
    "\r\n",
    "# Check the shapes of the resulting arrays\r\n",
    "print('X_Train Data Shape: ', X_train.shape)  # (20, 5, 4)\r\n",
    "print('y_Train Data Shape: ', y_train.shape)  # (20, 4)\r\n",
    "print('X_Test Data Shape: ', X_test.shape)    # (2, 5, 4)\r\n",
    "print('y_Test Data Shape: ', y_test.shape)    # (2, 4)\r\n",
    "```\r\n",
    "\r\n",
    "### Explanation of Shapes:\r\n",
    "- **X_train shape**: `(20, 5, 4)` means there are 20 sequences, each consisting of 5 frames, with 4 features per frame.\r\n",
    "- **y_train shape**: `(20, 4)` means there are 20 target frames, each having 4 features (corresponding to the next frame after each sequence).\r\n",
    "- **X_test shape**: `(2, 5, 4)` means there are 2 sequences in the test set\n",
    "32), each consisting of 5 frames.\r\n",
    "- **y_test shape**: `(2, 4)` means there are 2 target frames in the test set.\r\n",
    "\r\n",
    "In this example, you are predicting the next frame in a sequence of frames (like predicting the next move in a cricket stroke based on past moves)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9c037-e4eb-41f8-b4bc-b0deb6772305",
   "metadata": {},
   "source": [
    "### Predict the next 3 frames\n",
    "To modify the code to **predict the next 3 frames** instead of just the next one, you need to adjust the `create_sequences` function to generate **multiple future frames** as targets.\r\n",
    "\r\n",
    "Here's how you can update the code:\r\n",
    "\r\n",
    "### Changes Required:\r\n",
    "\r\n",
    "1. **X** (input) will remain the same: The past `timesteps` number of frames.\r\n",
    "2. **y** (target) will now be the next **3 consecutive frames** after the `timesteps` number of frames.\r\n",
    "\r\n",
    "### Updated `create_sequences` Function:\r\n",
    "\r\n",
    "- Instead of appending only one frame as the target (`y.append(data[i + timesteps])`), you will append the next 3 frames (`y.append(data[i + timesteps:i + timesteps + 3])`).\r\n",
    "- This will ensure that for every input sequence, there are 3 future frames as the target.\r\n",
    "\r\n",
    "### Code Update:\r\n",
    "\r\n",
    "```python\r\n",
    "# Parameters\r\n",
    "timesteps = 5  # Use 5 previous frames for prediction\r\n",
    "n_features = 4  # Each frame has 4 features\r\n",
    "train_size = 25\r\n",
    "test_size = 7\r\n",
    "n_future_frames = 3  # Predict the next 3 frames\r\n",
    "\r\n",
    "# Split the data into training and test sets\r\n",
    "train_data = Posdataset_numeric.iloc[:train_size].values  # First 25 frames\r\n",
    "test_data = Posdataset_numeric.iloc[train_size:train_size + test_size].values  # Next 7 frames\r\n",
    "\r\n",
    "# Function to create sequences (X as input, y as target with 3 future frames)\r\n",
    "def create_sequences(data, timesteps, n_future_frames):\r\n",
    "    X, y = [], []\r\n",
    "    for i in range(len(data) - timesteps - n_future_frames + 1):\r\n",
    "        X.append(data[i:i + timesteps])  # 5 frames as input\r\n",
    "        y.append(data[i + timesteps:i + timesteps + n_future_frames])  # Next 3 frames as output\r\n",
    "    return np.array(X), np.array(y)\r\n",
    "\r\n",
    "# Create sequences for training\r\n",
    "X_train, y_train = create_sequences(train_data, timesteps, n_future_frames)\r\n",
    "# Create sequences for testing\r\n",
    "X_test, y_test = create_sequences(test_data, timesteps, n_future_frames)\r\n",
    "\r\n",
    "# Check the shapes of the resulting arrays\r\n",
    "print('X_Train Data Shape: ', X_train.shape)  # Shape: (number of sequences, 5, 4)\r\n",
    "print('y_Train Data Shape: ', y_train.shape)  # Shape: (number of sequences, 3, 4)\r\n",
    "print('X_Test Data Shape: ', X_test.shape)    # Shape: (number of sequences, 5, 4)\r\n",
    "print('y_Test Data Shape: ', y_test.shape)    # Shape: (number of sequences, 3, 4)\r\n",
    "```\r\n",
    "\r\n",
    "### Explanation of Changes:\r\n",
    "\r\n",
    "1. **X (input)** remains a sequence of 5 frames (with `timesteps = 5`).\r\n",
    "2. **y (target)** now contains 3 future frames instead of just one.\r\n",
    "   - So, for every sequence of 5 frames in `X`, the target `y` will be the next 3 frames (each having 4 features).\r\n",
    "3. The sliding window logic is updated so that you only generate sequences where 3 future frames exist after the current sequence.\r\n",
    "\r\n",
    "### Example:\r\n",
    "\r\n",
    "Assume we have the following data (simplified example with random values):\r\n",
    "\r\n",
    "```\r\n",
    "Frame | Feature1 | Feature2 | Feature3 | Feature4\r\n",
    "---------------------------------------------------\r\n",
    "1     | 0.1      | 0.2      | 0.3      | 0.4\r\n",
    "2     | 0.5      | 0.6      | 0.7      | 0.8\r\n",
    "3     | 0.9      | 1.0      | 1.1      | 1.2\r\n",
    "4     | 1.3      | 1.4      | 1.5      | 1.6\r\n",
    "5     | 1.7      | 1.8      | 1.9      | 2.0\r\n",
    "6     | 2.1      | 2.2      | 2.3      | 2.4\r\n",
    "7     | 2.5      | 2.6      | 2.7      | 2.8\r\n",
    "8     | 2.9      | 3.0      | 3.1      | 3.2\r\n",
    "9     | 3.3      | 3.4      | 3.5      | 3.6\r\n",
    "...\r\n",
    "```\r\n",
    "\r\n",
    "For the first sequence:\r\n",
    "- **X** (input) will be frames 1 to 5:\r\n",
    "  ```\r\n",
    "  [[0.1, 0.2, 0.3, 0.4], \r\n",
    "   [0.5, 0.6, 0.7, 0.8], \r\n",
    "   [0.9, 1.0, 1.1, 1.2], \r\n",
    "   [1.3, 1.4, 1.5, 1.6], \r\n",
    "   [1.7, 1.8, 1.9, 2.0]]\r\n",
    "  ```\r\n",
    "- **y** (target) will be frames 6 to 8 (3 future frames):\r\n",
    "  ```\r\n",
    "  [[2.1, 2.2, 2.3, 2.4], \r\n",
    "   [2.5, 2.6, 2.7, 2.8], \r\n",
    "   [2.9, 3.0, 3.1, 3.2]]\r\n",
    "  ```\r\n",
    "\r\n",
    "### Shape of Output:\r\n",
    "\r\n",
    "1. **X_train shape**: `(number_of_sequences, timesteps, n_features)`\r\n",
    "   - Example: `(18, 5, 4)` → There are 18 sequences, each with 5 frames, and each frame has 4 features.\r\n",
    "2. **y_train shape**: `(number_of_sequences, n_future_frames, n_features)`\r\n",
    "   - Example: `(18, 3, 4)` → There are 18 sequences, each predicting 3 future frames, and each frame has 4 features.\r\n",
    "\r\n",
    "By predicting 3 future frames, the model can forecast more extended sequences based on the past frames, which is useful in scenarios like time-series forecasting or predicting movements in sports based on previous patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "04ce676f-dad8-435b-9ac8-8e9a9587e672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainData Shape:  (832, 132)\n",
      "TestData Shape:  (11, 132)\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "timesteps = 10  # Number of previous frames to use for prediction\n",
    "n_features = Posdataset_numeric.shape[1]  # Number of features\n",
    "train_size = len(Posdataset_numeric)-11  # Train on first 830 frames\n",
    "test_size = 11   # Test on the next 10 frames (831 to 840)\n",
    "\n",
    "#print(len(Posdataset_numeric))\n",
    "# Split the data into train and test sets\n",
    "train_data = Posdataset_numeric.iloc[:train_size].values\n",
    "test_data = Posdataset_numeric.iloc[train_size:train_size + test_size].values\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "print('TrainData Shape: ', train_data_scaled.shape)\n",
    "print('TestData Shape: ',test_data_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f794fd4-d956-4f1f-86e3-bfa7ad13872b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bf44e8b9-402f-45af-a046-5415fec83a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train Data Shape:  (822, 10, 132)\n",
      "y_Train Data Shape:  (822, 132)\n",
      "X_Test Data Shape:  (1, 10, 132)\n",
      "y_Test Data Shape:  (1, 132)\n"
     ]
    }
   ],
   "source": [
    "# Function to create sequences\n",
    "def create_sequences(data, timesteps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - timesteps):\n",
    "        X.append(data[i:i + timesteps])\n",
    "        y.append(data[i + timesteps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create sequences from the scaled data\n",
    "X_train, y_train = create_sequences(train_data_scaled, timesteps)\n",
    "X_test, y_test = create_sequences(test_data_scaled, timesteps)\n",
    "\n",
    "print('X_Train Data Shape: ', X_train.shape)\n",
    "print('y_Train Data Shape: ', y_train.shape)\n",
    "print('X_Test Data Shape: ',X_test.shape)\n",
    "print('y_Test Data Shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e693ae6-6a52-4b49-8d50-927ac443129b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1051c0be-77de-44ca-8268-fc543562c6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (822, 1, 132)\n",
      "y_test shape: (1, 1, 132)\n"
     ]
    }
   ],
   "source": [
    "# Reshape y_train and y_test to include the time dimension\n",
    "y_train = y_train.reshape(y_train.shape[0], 1, y_train.shape[1])  # Shape: (820, 1, n_features)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1, y_test.shape[1])      # Shape: (1, 1, n_features)\n",
    "\n",
    "\n",
    "# Check the shapes to ensure they are correct\n",
    "print(\"y_train shape:\", y_train.shape)  # Should be (samples, 1, n_features)\n",
    "print(\"y_test shape:\", y_test.shape)    # Should be (samples, 1, n_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7b5ac-83fb-4b87-a85d-6df8d4d29b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9f5ba3fb-91d8-48ee-9959-615243e47d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and train Transformer model\n",
    "def build_transformer_model():\n",
    "    input_layer = Input(shape=(timesteps, n_features))\n",
    "    attention_output = MultiHeadAttention(num_heads=4, key_dim=n_features)(input_layer, input_layer)\n",
    "    attention_output = LayerNormalization(epsilon=1e-6)(attention_output)\n",
    "    transformer_output = Dense(64, activation='relu')(attention_output)\n",
    "    transformer_output = Dropout(0.2)(transformer_output)\n",
    "    output = Dense(n_features)(transformer_output)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the model\n",
    "model = build_transformer_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ae326e80-72f7-4e2a-9883-d5d6b3b67a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 132)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "305cb3dd-2847-4872-b4be-d70ace8face4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0275 - val_loss: 0.0056\n",
      "Epoch 2/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0262 - val_loss: 0.0053\n",
      "Epoch 3/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0265 - val_loss: 0.0048\n",
      "Epoch 4/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0259 - val_loss: 0.0043\n",
      "Epoch 5/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0256 - val_loss: 0.0038\n",
      "Epoch 6/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0257 - val_loss: 0.0055\n",
      "Epoch 7/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0250 - val_loss: 0.0049\n",
      "Epoch 8/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0240 - val_loss: 0.0041\n",
      "Epoch 9/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0242 - val_loss: 0.0038\n",
      "Epoch 10/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0233 - val_loss: 0.0042\n",
      "Epoch 11/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0237 - val_loss: 0.0056\n",
      "Epoch 12/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0227 - val_loss: 0.0042\n",
      "Epoch 13/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0222 - val_loss: 0.0042\n",
      "Epoch 14/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0222 - val_loss: 0.0084\n",
      "Epoch 15/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0225 - val_loss: 0.0057\n",
      "Epoch 16/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0221 - val_loss: 0.0048\n",
      "Epoch 17/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0216 - val_loss: 0.0040\n",
      "Epoch 18/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0210 - val_loss: 0.0054\n",
      "Epoch 19/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0208 - val_loss: 0.0043\n",
      "Epoch 20/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0210 - val_loss: 0.0047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    }
   ],
   "source": [
    "# Number of epochs and batch size\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "# Fit the model on the training data and validate on the test data\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)\n",
    "# Predict the next frames\n",
    "# Predict the next frames\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d56d21-ae2f-449e-a547-332c3dc05868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a9e38346-42de-49bf-ace0-fabf494e528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (1, 10, 132)\n",
      "y_test shape before reshaping: (1, 1, 132)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of predictions and y_test before reshaping\n",
    "print(\"Predictions shape:\", predictions.shape)\n",
    "print(\"y_test shape before reshaping:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f7bbe7-7c71-46d1-b3ef-9e9b37fbac2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a2339fbe-06cf-443a-80f6-e0cd3e63bec2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions reshaped shape: (1, 132)\n",
      "y_test_reshaped: (1, 132)\n",
      "y_test_rescaled: (1, 132) <class 'numpy.ndarray'>\n",
      "Transformer Model MSE: 0.0007538144151298676\n"
     ]
    }
   ],
   "source": [
    "# Reshape predictions by flattening time steps into the batch dimension\n",
    "#predictions_reshaped = predictions.reshape(predictions.shape[0], -1)\n",
    "# Take the last time step's predictions (for example, if you're interested in the last time step)\n",
    "predictions_reshaped = predictions[:, -1, :]\n",
    "y_test_reshaped = y_test[:, -1, :]\n",
    "\n",
    "print(\"Predictions reshaped shape:\", predictions_reshaped.shape)\n",
    "print(\"y_test_reshaped:\", y_test_reshaped.shape)\n",
    "# Rescale predictions back to original values\n",
    "predictions_rescaled = scaler.inverse_transform(predictions_reshaped)\n",
    "y_test_rescaled = scaler.inverse_transform(y_test_reshaped)\n",
    "print(\"y_test_rescaled:\", y_test_rescaled.shape, type(y_test_rescaled))\n",
    "# Calculate error\n",
    "mse = mean_squared_error(y_test_rescaled, predictions_rescaled)\n",
    "print(f'Transformer Model MSE: {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9e4b2137-f0c4-4896-b81c-a2006060731f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(predictions_rescaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "36bc6ddd-c6b1-4c53-b071-abe63c07d7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted frames:\n",
      "[[ 3.9956656e-01  4.3985844e-01 -1.4939047e-01  9.9968761e-01\n",
      "   4.0712228e-01  4.3592298e-01 -1.4596486e-01  9.9942440e-01\n",
      "   4.0762785e-01  4.2930570e-01 -1.3614281e-01  9.9938035e-01\n",
      "   4.0560079e-01  4.3806753e-01 -1.4055437e-01  9.9959707e-01\n",
      "   3.9746985e-01  4.3336329e-01 -1.3600844e-01  9.9975044e-01\n",
      "   3.9656636e-01  4.4129357e-01 -1.4156111e-01  9.9941349e-01\n",
      "   3.9890176e-01  4.4442809e-01 -1.3635139e-01  9.9941880e-01\n",
      "   4.1330662e-01  4.3065986e-01 -9.5798507e-02  9.9931043e-01\n",
      "   3.9893588e-01  4.4109905e-01 -6.1210148e-02  9.9901485e-01\n",
      "   4.1381541e-01  4.5284590e-01 -1.4021988e-01  9.9946082e-01\n",
      "   4.0566331e-01  4.5163643e-01 -1.2420874e-01  9.9839884e-01\n",
      "   4.3571264e-01  4.3908972e-01 -9.0509735e-02  9.9894738e-01\n",
      "   4.0454918e-01  4.9051833e-01  4.5107477e-04  9.9609143e-01\n",
      "   4.4806966e-01  3.8597009e-01 -1.5999867e-01  9.8893803e-01\n",
      "   3.9528346e-01  5.1513433e-01 -5.9583869e-02  9.2917347e-01\n",
      "   4.0263802e-01  4.0332076e-01 -1.7283225e-01  8.6507857e-01\n",
      "   3.8818294e-01  4.4683123e-01 -1.3264060e-01  8.7989956e-01\n",
      "   4.0096352e-01  4.0616420e-01 -1.8765245e-01  7.2175509e-01\n",
      "   3.7468666e-01  4.3488130e-01 -1.5063871e-01  7.6268351e-01\n",
      "   4.0152532e-01  4.1217443e-01 -1.5359551e-01  7.1663642e-01\n",
      "   3.8477606e-01  4.4532296e-01 -1.4525495e-01  7.3196208e-01\n",
      "   4.0629399e-01  4.1569212e-01 -1.6385198e-01  6.7859548e-01\n",
      "   3.9524898e-01  4.3661717e-01 -1.3491154e-01  7.0579654e-01\n",
      "   4.7800252e-01  5.8068466e-01 -4.8210010e-02  9.9988991e-01\n",
      "   4.5779210e-01  5.9684694e-01  5.0489973e-02  9.9956501e-01\n",
      "   4.3993613e-01  6.6441870e-01 -1.3129830e-01  1.0102057e+00\n",
      "   4.7375330e-01  6.7401665e-01  1.7630650e-01  9.1829914e-01\n",
      "   4.4785395e-01  7.6683480e-01 -1.2303040e-01  1.0035591e+00\n",
      "   5.2200121e-01  7.0743769e-01  3.2458326e-01  9.7481972e-01\n",
      "   4.5542434e-01  7.8611302e-01 -1.2065825e-01  1.0005673e+00\n",
      "   5.3195393e-01  7.0713484e-01  3.3659244e-01  9.6202749e-01\n",
      "   4.2526317e-01  8.0299604e-01 -1.8971339e-01  1.0014122e+00\n",
      "   5.1035941e-01  7.4701983e-01  3.0328560e-01  9.4860500e-01]]\n",
      "Actual frames:\n",
      "[[ 0.3722809   0.42554882 -0.13629444  0.99978524  0.37158236  0.41189712\n",
      "  -0.12996903  0.99961901  0.37287459  0.40885472 -0.12996475  0.99957114\n",
      "   0.37412536  0.40599263 -0.1300083   0.99967855  0.3687093   0.41751626\n",
      "  -0.1201245   0.99973583  0.36819479  0.41829491 -0.12014101  0.99960822\n",
      "   0.36769307  0.41882893 -0.12014638  0.99970567  0.37976697  0.40041244\n",
      "  -0.08859272  0.99950743  0.37235478  0.41613337 -0.04196393  0.99947453\n",
      "   0.38067573  0.42574325 -0.12141642  0.99966729  0.37667874  0.43285507\n",
      "  -0.10813376  0.9994058   0.41265452  0.41289711 -0.09537252  0.998851\n",
      "   0.38130865  0.46703377  0.01784974  0.99682814  0.41166747  0.33696535\n",
      "  -0.15463336  0.99562365  0.37630573  0.49181688 -0.02939172  0.96714479\n",
      "   0.37419748  0.36711857 -0.10823104  0.90942973  0.35799703  0.41901261\n",
      "  -0.10160434  0.92066085  0.3633858   0.37132651 -0.11874367  0.72532082\n",
      "   0.35318291  0.402271   -0.11898687  0.79416549  0.36529043  0.37871799\n",
      "  -0.10507677  0.69203013  0.35465863  0.40314543 -0.10077474  0.76816261\n",
      "   0.37038389  0.38096264 -0.1023413   0.67704499  0.35836774  0.40887153\n",
      "  -0.09852925  0.73914695  0.46109658  0.55687028 -0.04881568  0.99984205\n",
      "   0.44098225  0.57112831  0.04886281  0.99922729  0.43244484  0.65053809\n",
      "  -0.09319297  0.99754763  0.46202627  0.63031572  0.19600788  0.83498579\n",
      "   0.43357342  0.75320411 -0.09166483  0.99761939  0.48920113  0.68872178\n",
      "   0.33082345  0.93139929  0.4414821   0.77183276 -0.09293153  0.9944818\n",
      "   0.4973194   0.69371593  0.34341651  0.93410337  0.40794614  0.78896654\n",
      "  -0.15176164  0.99392945  0.48246974  0.73133028  0.31871539  0.93446541]]\n"
     ]
    }
   ],
   "source": [
    "# Print predicted vs actual frames for comparison\n",
    "print(\"Predicted frames:\")\n",
    "print(predictions_rescaled)\n",
    "print(\"Actual frames:\")\n",
    "print(y_test_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6c2aa885-f4fe-450d-9960-dce5b800d52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 132)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(\"Predicted Pose Points for Next Frame:\", len(predicted_frame[0]))  # Extract the predicted pose points\n",
    "\n",
    "print(predictions_rescaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0c0aa01e-df60-461f-aa74-b0eaba20a279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Frame:  [[ 3.9956656e-01  4.3985844e-01 -1.4939047e-01  9.9968761e-01\n",
      "   4.0712228e-01  4.3592298e-01 -1.4596486e-01  9.9942440e-01\n",
      "   4.0762785e-01  4.2930570e-01 -1.3614281e-01  9.9938035e-01\n",
      "   4.0560079e-01  4.3806753e-01 -1.4055437e-01  9.9959707e-01\n",
      "   3.9746985e-01  4.3336329e-01 -1.3600844e-01  9.9975044e-01\n",
      "   3.9656636e-01  4.4129357e-01 -1.4156111e-01  9.9941349e-01\n",
      "   3.9890176e-01  4.4442809e-01 -1.3635139e-01  9.9941880e-01\n",
      "   4.1330662e-01  4.3065986e-01 -9.5798507e-02  9.9931043e-01\n",
      "   3.9893588e-01  4.4109905e-01 -6.1210148e-02  9.9901485e-01\n",
      "   4.1381541e-01  4.5284590e-01 -1.4021988e-01  9.9946082e-01\n",
      "   4.0566331e-01  4.5163643e-01 -1.2420874e-01  9.9839884e-01\n",
      "   4.3571264e-01  4.3908972e-01 -9.0509735e-02  9.9894738e-01\n",
      "   4.0454918e-01  4.9051833e-01  4.5107477e-04  9.9609143e-01\n",
      "   4.4806966e-01  3.8597009e-01 -1.5999867e-01  9.8893803e-01\n",
      "   3.9528346e-01  5.1513433e-01 -5.9583869e-02  9.2917347e-01\n",
      "   4.0263802e-01  4.0332076e-01 -1.7283225e-01  8.6507857e-01\n",
      "   3.8818294e-01  4.4683123e-01 -1.3264060e-01  8.7989956e-01\n",
      "   4.0096352e-01  4.0616420e-01 -1.8765245e-01  7.2175509e-01\n",
      "   3.7468666e-01  4.3488130e-01 -1.5063871e-01  7.6268351e-01\n",
      "   4.0152532e-01  4.1217443e-01 -1.5359551e-01  7.1663642e-01\n",
      "   3.8477606e-01  4.4532296e-01 -1.4525495e-01  7.3196208e-01\n",
      "   4.0629399e-01  4.1569212e-01 -1.6385198e-01  6.7859548e-01\n",
      "   3.9524898e-01  4.3661717e-01 -1.3491154e-01  7.0579654e-01\n",
      "   4.7800252e-01  5.8068466e-01 -4.8210010e-02  9.9988991e-01\n",
      "   4.5779210e-01  5.9684694e-01  5.0489973e-02  9.9956501e-01\n",
      "   4.3993613e-01  6.6441870e-01 -1.3129830e-01  1.0102057e+00\n",
      "   4.7375330e-01  6.7401665e-01  1.7630650e-01  9.1829914e-01\n",
      "   4.4785395e-01  7.6683480e-01 -1.2303040e-01  1.0035591e+00\n",
      "   5.2200121e-01  7.0743769e-01  3.2458326e-01  9.7481972e-01\n",
      "   4.5542434e-01  7.8611302e-01 -1.2065825e-01  1.0005673e+00\n",
      "   5.3195393e-01  7.0713484e-01  3.3659244e-01  9.6202749e-01\n",
      "   4.2526317e-01  8.0299604e-01 -1.8971339e-01  1.0014122e+00\n",
      "   5.1035941e-01  7.4701983e-01  3.0328560e-01  9.4860500e-01]]\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "#Posdataset\n",
    "data = Posdataset.drop(columns=['Unnamed: 0'])\n",
    "Features=data.drop( ['Label'], axis=1)\n",
    "#print(Features)\n",
    "# Assuming 'newdataset' is your DataFrame\n",
    "columns_list = Features.columns.tolist()\n",
    "\n",
    "# nt the list of column names\n",
    "#print(columns_list)\n",
    "preframes=predictions_rescaled\n",
    "print('Predicted Frame: ',preframes)\n",
    "print(len(columns_list))\n",
    "\n",
    "# Reshape frames to 2D (if it is a 3D array)\n",
    "preframes = preframes.reshape(1, 132)\n",
    "\n",
    "# Now create the DataFrame\n",
    "PredictedFrame = pd.DataFrame(preframes, columns=columns_list)\n",
    "\n",
    "orgframes = y_test_rescaled\n",
    "orgframes = orgframes.reshape(1, 132)\n",
    "OrignalFrame = pd.DataFrame(orgframes, columns=columns_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d3aa0580-a60c-4e2f-ad9f-0936132cf0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Test\\AppData\\Local\\Temp\\ipykernel_19416\\2052921703.py:39: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x = predicted_row[i] * width  # Assuming x is normalized, scale to image width\n",
      "C:\\Users\\Test\\AppData\\Local\\Temp\\ipykernel_19416\\2052921703.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y = predicted_row[i + 1] * height  # Assuming y is normalized, scale to image height\n",
      "C:\\Users\\Test\\AppData\\Local\\Temp\\ipykernel_19416\\2052921703.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x = original_row[i] * width  # Assuming x is normalized, scale to image width\n",
      "C:\\Users\\Test\\AppData\\Local\\Temp\\ipykernel_19416\\2052921703.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y = original_row[i + 1] * height  # Assuming y is normalized, scale to image height\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting on 'q' key press\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Test\\AppData\\Local\\Temp\\ipykernel_19416\\2052921703.py:129: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x = predicted_row[i] * width  # Assuming x is normalized, scale to image width\n",
      "C:\\Users\\Test\\AppData\\Local\\Temp\\ipykernel_19416\\2052921703.py:130: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y = predicted_row[i + 1] * height  # Assuming y is normalized, scale to image height\n",
      "C:\\Users\\Test\\AppData\\Local\\Temp\\ipykernel_19416\\2052921703.py:137: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x = original_row[i] * width  # Assuming x is normalized, scale to image width\n",
      "C:\\Users\\Test\\AppData\\Local\\Temp\\ipykernel_19416\\2052921703.py:138: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y = original_row[i + 1] * height  # Assuming y is normalized, scale to image height\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Select only the columns that contain x, y, and z coordinates\n",
    "xyz_columns = [col for col in PredictedFrame.columns if '_x' in col or '_y' in col or '_z' in col]\n",
    "predicted_xyz = PredictedFrame[xyz_columns]\n",
    "original_xyz = OrignalFrame[xyz_columns]\n",
    "\n",
    "# Define connections between keypoints to draw the skeleton based on F1 to F32\n",
    "connections = [\n",
    "    (0, 1), (1, 2), (2, 3),  # Left eye connections\n",
    "    (0, 4), (4, 5), (5, 6),  # Right eye connections\n",
    "    (0, 7), (0, 8),  # Nose to ears\n",
    "    (9, 10),  # Mouth connection\n",
    "    (11, 12),  # Shoulders\n",
    "    (11, 13), (13, 15),  # Left arm (shoulder, elbow, wrist)\n",
    "    (15, 17), (15, 19), (15, 21),  # Left hand (wrist to pinky, index, thumb)\n",
    "    (12, 14), (14, 16),  # Right arm (shoulder, elbow, wrist)\n",
    "    (16, 18), (16, 20), (16, 22),  # Right hand (wrist to pinky, index, thumb)\n",
    "    (23, 24),  # Hips\n",
    "    (11, 23), (12, 24),  # Shoulders to hips\n",
    "    (23, 25), (25, 27), (27, 29), (27, 31),  # Left leg (hip, knee, ankle, heel, foot index)\n",
    "    (24, 26), (26, 28), (28, 30), (28, 32),  # Right leg (hip, knee, ankle, heel, foot index)\n",
    "]\n",
    "\n",
    "# Create a blank image (adjust size according to your coordinates)\n",
    "width, height = 640, 480  # Adjust size as needed\n",
    "\n",
    "# Loop through each row (frame) in the DataFrame to draw the skeleton for each frame\n",
    "for index in range(len(predicted_xyz)):\n",
    "    # Clear the image for each frame\n",
    "    blank_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Extract (x, y) coordinates from the predicted row\n",
    "    predicted_row = predicted_xyz.iloc[index]\n",
    "    predicted_keypoints = []\n",
    "    for i in range(0, len(predicted_row), 3):  # Skip every 3rd value because of the x, y, z format\n",
    "        x = predicted_row[i] * width  # Assuming x is normalized, scale to image width\n",
    "        y = predicted_row[i + 1] * height  # Assuming y is normalized, scale to image height\n",
    "        predicted_keypoints.append((int(x), int(y)))\n",
    "\n",
    "    # Extract (x, y) coordinates from the original row\n",
    "    original_row = original_xyz.iloc[index]\n",
    "    original_keypoints = []\n",
    "    for i in range(0, len(original_row), 3):  # Skip every 3rd value because of the x, y, z format\n",
    "        x = original_row[i] * width  # Assuming x is normalized, scale to image width\n",
    "        y = original_row[i + 1] * height  # Assuming y is normalized, scale to image height\n",
    "        original_keypoints.append((int(x), int(y)))\n",
    "\n",
    "    # Draw circles at each keypoint for the predicted frame (color: green)\n",
    "    for (x, y) in predicted_keypoints:\n",
    "        cv2.circle(blank_image, (x, y), 5, (0, 255, 0), cv2.FILLED)\n",
    "\n",
    "    # Draw lines to form the skeleton for the predicted frame (color: blue)\n",
    "    for connection in connections:\n",
    "        point1 = connection[0]\n",
    "        point2 = connection[1]\n",
    "        if point1 < len(predicted_keypoints) and point2 < len(predicted_keypoints):\n",
    "            cv2.line(blank_image, predicted_keypoints[point1], predicted_keypoints[point2], (0, 255, 0), 2)\n",
    "\n",
    "    # Draw circles at each keypoint for the original frame (color: red)\n",
    "    for (x, y) in original_keypoints:\n",
    "        cv2.circle(blank_image, (x, y), 5, (0, 0, 255), cv2.FILLED)\n",
    "\n",
    "    # Draw lines to form the skeleton for the original frame (color: yellow)\n",
    "    for connection in connections:\n",
    "        point1 = connection[0]\n",
    "        point2 = connection[1]\n",
    "        if point1 < len(original_keypoints) and point2 < len(original_keypoints):\n",
    "            cv2.line(blank_image, original_keypoints[point1], original_keypoints[point2], (0, 0, 255), 2)\n",
    "\n",
    "    # Add text to indicate which color represents original and predicted\n",
    "    cv2.putText(blank_image, 'Original: Pose Red', (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "    cv2.putText(blank_image, 'Predicted: Pose Green', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    #cv2.putText(blank_image, 'Original: Shot ' + str(Org_label[0]), (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "    #cv2.putText(blank_image, 'Predicted: Shot ' + str(pred_label[0]), (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the skeleton for this frame\n",
    "    cv2.imshow('Skeleton Comparison', blank_image)\n",
    "    \n",
    "    key = cv2.waitKey(50000) & 0xFF  # Adjust wait time to 30 milliseconds\n",
    "    if key == ord('q'):\n",
    "        print(\"Exiting on 'q' key press\")\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Select only the columns that contain x, y, and z coordinates\n",
    "xyz_columns = [col for col in PredictedFrame.columns if '_x' in col or '_y' in col or '_z' in col]\n",
    "predicted_xyz = PredictedFrame[xyz_columns]\n",
    "original_xyz = OrignalFrame[xyz_columns]\n",
    "\n",
    "# Define connections between keypoints to draw the skeleton based on F1 to F32\n",
    "connections = [\n",
    "    (0, 1), (1, 2), (2, 3),  # Left eye connections\n",
    "    (0, 4), (4, 5), (5, 6),  # Right eye connections\n",
    "    (0, 7), (0, 8),  # Nose to ears\n",
    "    (9, 10),  # Mouth connection\n",
    "    (11, 12),  # Shoulders\n",
    "    (11, 13), (13, 15),  # Left arm (shoulder, elbow, wrist)\n",
    "    (15, 17), (15, 19), (15, 21),  # Left hand (wrist to pinky, index, thumb)\n",
    "    (12, 14), (14, 16),  # Right arm (shoulder, elbow, wrist)\n",
    "    (16, 18), (16, 20), (16, 22),  # Right hand (wrist to pinky, index, thumb)\n",
    "    (23, 24),  # Hips\n",
    "    (11, 23), (12, 24),  # Shoulders to hips\n",
    "    (23, 25), (25, 27), (27, 29), (27, 31),  # Left leg (hip, knee, ankle, heel, foot index)\n",
    "    (24, 26), (26, 28), (28, 30), (28, 32),  # Right leg (hip, knee, ankle, heel, foot index)\n",
    "]\n",
    "\n",
    "# Create a blank image (adjust size according to your coordinates)\n",
    "width, height = 640, 480  # Adjust size as needed\n",
    "\n",
    "# Loop through each row (frame) in the DataFrame to draw the skeleton for each frame\n",
    "for index in range(len(predicted_xyz)):\n",
    "    # Clear images for each frame\n",
    "    blank_image_predicted = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    blank_image_original = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Extract (x, y) coordinates from the predicted row\n",
    "    predicted_row = predicted_xyz.iloc[index]\n",
    "    predicted_keypoints = []\n",
    "    for i in range(0, len(predicted_row), 3):  # Skip every 3rd value because of the x, y, z format\n",
    "        x = predicted_row[i] * width  # Assuming x is normalized, scale to image width\n",
    "        y = predicted_row[i + 1] * height  # Assuming y is normalized, scale to image height\n",
    "        predicted_keypoints.append((int(x), int(y)))\n",
    "\n",
    "    # Extract (x, y) coordinates from the original row\n",
    "    original_row = original_xyz.iloc[index]\n",
    "    original_keypoints = []\n",
    "    for i in range(0, len(original_row), 3):  # Skip every 3rd value because of the x, y, z format\n",
    "        x = original_row[i] * width  # Assuming x is normalized, scale to image width\n",
    "        y = original_row[i + 1] * height  # Assuming y is normalized, scale to image height\n",
    "        original_keypoints.append((int(x), int(y)))\n",
    "\n",
    "    # Draw circles and lines for the predicted frame (color: green)\n",
    "    for (x, y) in predicted_keypoints:\n",
    "        cv2.circle(blank_image_predicted, (x, y), 5, (0, 255, 0), cv2.FILLED)\n",
    "    for connection in connections:\n",
    "        point1, point2 = connection\n",
    "        if point1 < len(predicted_keypoints) and point2 < len(predicted_keypoints):\n",
    "            cv2.line(blank_image_predicted, predicted_keypoints[point1], predicted_keypoints[point2], (0, 255, 0), 2)\n",
    "\n",
    "    # Draw circles and lines for the original frame (color: red)\n",
    "    for (x, y) in original_keypoints:\n",
    "        cv2.circle(blank_image_original, (x, y), 5, (0, 0, 255), cv2.FILLED)\n",
    "    for connection in connections:\n",
    "        point1, point2 = connection\n",
    "        if point1 < len(original_keypoints) and point2 < len(original_keypoints):\n",
    "            cv2.line(blank_image_original, original_keypoints[point1], original_keypoints[point2], (0, 0, 255), 2)\n",
    "\n",
    "    # Add text for frame labels\n",
    "    cv2.putText(blank_image_original, 'Original', (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "    cv2.putText(blank_image_predicted, 'Predicted', (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # Concatenate the two images side by side\n",
    "    comparison_image = np.hstack((blank_image_original, blank_image_predicted))\n",
    "\n",
    "    # Display the side-by-side comparison\n",
    "    cv2.imshow('Original vs Predicted Posture', comparison_image)\n",
    "\n",
    "    # Wait for keypress or a delay between frames\n",
    "    key = cv2.waitKey(50000) & 0xFF  # Adjust the delay as needed\n",
    "    if key == ord('q'):\n",
    "        print(\"Exiting on 'q' key press\")\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea2979-a711-4eb9-af19-44b5281368cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe72820b-6eb6-46b2-9a5b-1bbfd9aa25ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c9f4f-f4e9-4411-a1e2-c86a2b3f27c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53455f-f58b-428f-9ad0-d4e5306be005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
